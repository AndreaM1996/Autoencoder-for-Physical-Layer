{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gmpi - one-hot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtUTDH/Ki6M0wBxoEVL4Kc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreaM1996/Autoencoder-for-Physical-Layer/blob/master/Gmpi_one_hot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bn01wrbJuM6",
        "colab_type": "code",
        "outputId": "343cb838-0f28-4c1b-9f48-a77313478248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Lambda, BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTyYZhQLCveX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 7\n",
        "k = 4\n",
        "M = 2**k\n",
        "R = k/n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_pn1AmdfCgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(samples, max_features):\n",
        "  \"\"\"\n",
        "  Transforms dataset into one-hot encoding of that dataset\n",
        "\n",
        "  samples - dataset of size (No_samples, max_length)\n",
        "  max_features - maximal number of words in vocabulary\n",
        "  \"\"\"\n",
        "  results = np.zeros((len(samples), max_features))\n",
        "  for i, sample in enumerate(samples):\n",
        "    results[i, sample] = 1.\n",
        "\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6tvvYv9tXK6",
        "colab_type": "text"
      },
      "source": [
        "# **Load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETvqSMFTtYwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rng = np.random.default_rng()\n",
        "train = rng.integers(0, M, size=16000)\n",
        "val = rng.integers(0, M, size=50000)\n",
        "test = rng.integers(0, M, size=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCg2DKHWtcXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = one_hot(train, M)\n",
        "x_val = one_hot(val, M)\n",
        "x_test = one_hot(test, M)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m732naiuYJ1V",
        "colab_type": "text"
      },
      "source": [
        "# **Autoencoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8u9mGLdJBas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def autoencoder(in_dim, n_dim, std):\n",
        "  \n",
        "  input_ = Input(shape=(in_dim,))\n",
        "    \n",
        "  # Encoder layers - Transmitter\n",
        "  encoded1 = Dense(in_dim, activation='relu', name='encoder_layer1')(input_)\n",
        "  encoded2 = Dense(n_dim, activation='linear', name='encoder_layer2')(encoded1)\n",
        "  \n",
        "  # Normalization\n",
        "  normalized = Lambda(lambda x: np.sqrt(n_dim) * K.l2_normalize(x, axis=1), name='normalization')(encoded2) #energy constraint\n",
        "  #normalized = Lambda(lambda x: x / K.sqrt(K.mean(x**2)), name='normalization')(encoded2) #average power enegry constraint\n",
        "\n",
        "  # Channel\n",
        "  channel = Lambda(lambda x: x + K.random_normal(shape=(n_dim,), mean=0, stddev=std, seed=42), name='channel')(normalized)\n",
        "\n",
        "  # Decoder layers - Receiver\n",
        "  decoded1 = Dense(in_dim, activation='relu', name='decoder_layer1')(channel)\n",
        "  decoded2 = Dense(in_dim, activation='softmax', name='decoder_layer2')(decoded1)\n",
        "  \n",
        "\n",
        "  # Combine Encoder and Decoder layers\n",
        "  autoencoder = Model(inputs = input_, outputs = decoded2)\n",
        "\n",
        "  # Compile the Model \n",
        "  adam = optimizers.Adam(lr=0.001) \n",
        "  autoencoder.compile(optimizer = adam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  \n",
        "  encoder = Model(inputs=input_, outputs=normalized)\n",
        "\n",
        "  return autoencoder, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs6DoAQoR1l2",
        "colab_type": "text"
      },
      "source": [
        "# **Training and performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg-cviPET3-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_bler_vs_ebno(blers, ebno):\n",
        "  plt.figure(figsize=(6,6))\n",
        "  plt.scatter(ebno, blers,label='autoencoder (8,8)')\n",
        "  plt.plot\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('$E_b$/$N_0$ [db]', fontsize=15)\n",
        "  plt.ylabel('Block error rate', fontsize=15)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDdvN6Ez4-kr",
        "colab_type": "text"
      },
      "source": [
        "BLER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5iwzU6vNt1N",
        "colab_type": "code",
        "outputId": "3620355a-c0f9-4252-e839-745cfd9c78b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "snr = range(11)\n",
        "blers = []\n",
        "for db in snr:\n",
        "  Eb_No = 10**(db/10)\n",
        "  std = math.sqrt(1/(2 * R * Eb_No))\n",
        "  ae, encoder = autoencoder(M, n, std)\n",
        "  history = ae.fit(x_train, x_train, epochs = 50, batch_size = 100, shuffle = True, validation_data = (x_val, x_val))\n",
        "  pred = ae.predict(x_test)\n",
        "  predicted = np.argmax(pred, axis=1)\n",
        "  diff = np.sum(test != predicted)\n",
        "  bler = diff / predicted.shape[0]\n",
        "  blers.append(bler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.3574 - accuracy: 0.2955 - val_loss: 1.8422 - val_accuracy: 0.5157\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.5660 - accuracy: 0.6000 - val_loss: 1.3270 - val_accuracy: 0.6766\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.2017 - accuracy: 0.6921 - val_loss: 1.0763 - val_accuracy: 0.7024\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.9497 - accuracy: 0.7541 - val_loss: 0.9271 - val_accuracy: 0.7386\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.8886 - accuracy: 0.7342 - val_loss: 0.8399 - val_accuracy: 0.7470\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.8379 - accuracy: 0.7341 - val_loss: 0.7910 - val_accuracy: 0.7564\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7844 - accuracy: 0.7551 - val_loss: 0.7815 - val_accuracy: 0.7496\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7440 - accuracy: 0.7667 - val_loss: 0.7226 - val_accuracy: 0.7714\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7008 - accuracy: 0.7866 - val_loss: 0.7231 - val_accuracy: 0.7679\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.7425 - accuracy: 0.7578 - val_loss: 0.7504 - val_accuracy: 0.7485\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6559 - accuracy: 0.7869 - val_loss: 0.7843 - val_accuracy: 0.7355\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7647 - accuracy: 0.7391 - val_loss: 0.7295 - val_accuracy: 0.7586\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6519 - accuracy: 0.7853 - val_loss: 0.7307 - val_accuracy: 0.7658\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.6757 - accuracy: 0.7701 - val_loss: 0.6944 - val_accuracy: 0.7762\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6797 - accuracy: 0.7749 - val_loss: 0.6637 - val_accuracy: 0.7807\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6850 - accuracy: 0.7590 - val_loss: 0.7203 - val_accuracy: 0.7630\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6267 - accuracy: 0.8000 - val_loss: 0.6831 - val_accuracy: 0.7655\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6507 - accuracy: 0.7733 - val_loss: 0.6752 - val_accuracy: 0.7740\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6415 - accuracy: 0.7896 - val_loss: 0.6684 - val_accuracy: 0.7778\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6439 - accuracy: 0.7811 - val_loss: 0.6116 - val_accuracy: 0.7972\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7117 - accuracy: 0.7715 - val_loss: 0.6644 - val_accuracy: 0.7763\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6577 - accuracy: 0.7779 - val_loss: 0.6735 - val_accuracy: 0.7652\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6756 - accuracy: 0.7824 - val_loss: 0.5894 - val_accuracy: 0.8004\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6361 - accuracy: 0.7856 - val_loss: 0.6642 - val_accuracy: 0.7829\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6388 - accuracy: 0.7872 - val_loss: 0.6902 - val_accuracy: 0.7714\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6340 - accuracy: 0.7797 - val_loss: 0.6802 - val_accuracy: 0.7668\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6813 - accuracy: 0.7776 - val_loss: 0.6724 - val_accuracy: 0.7818\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7045 - accuracy: 0.7775 - val_loss: 0.6987 - val_accuracy: 0.7650\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6225 - accuracy: 0.7903 - val_loss: 0.6829 - val_accuracy: 0.7659\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7304 - accuracy: 0.7408 - val_loss: 0.6221 - val_accuracy: 0.7881\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7253 - accuracy: 0.7702 - val_loss: 0.7017 - val_accuracy: 0.7657\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.7719 - val_loss: 0.6967 - val_accuracy: 0.7709\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7960 - accuracy: 0.7413 - val_loss: 0.6911 - val_accuracy: 0.7685\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7213 - accuracy: 0.7480 - val_loss: 0.7106 - val_accuracy: 0.7582\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7399 - accuracy: 0.7477 - val_loss: 0.6920 - val_accuracy: 0.7664\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6992 - accuracy: 0.7501 - val_loss: 0.6985 - val_accuracy: 0.7694\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6443 - accuracy: 0.7869 - val_loss: 0.6359 - val_accuracy: 0.7896\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.7318 - accuracy: 0.7486 - val_loss: 0.6604 - val_accuracy: 0.7804\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6823 - accuracy: 0.7794 - val_loss: 0.5942 - val_accuracy: 0.8027\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7007 - accuracy: 0.7638 - val_loss: 0.7034 - val_accuracy: 0.7681\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6194 - accuracy: 0.7923 - val_loss: 0.6485 - val_accuracy: 0.7821\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6045 - accuracy: 0.8084 - val_loss: 0.6490 - val_accuracy: 0.7811\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.6809 - accuracy: 0.7768 - val_loss: 0.6431 - val_accuracy: 0.7806\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5920 - accuracy: 0.8048 - val_loss: 0.6580 - val_accuracy: 0.7802\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5915 - accuracy: 0.8056 - val_loss: 0.6744 - val_accuracy: 0.7691\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6262 - accuracy: 0.8020 - val_loss: 0.6818 - val_accuracy: 0.7739\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.6283 - accuracy: 0.7829 - val_loss: 0.6543 - val_accuracy: 0.7797\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6731 - accuracy: 0.7738 - val_loss: 0.6633 - val_accuracy: 0.7844\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.7784 - accuracy: 0.7489 - val_loss: 0.6686 - val_accuracy: 0.7773\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6127 - accuracy: 0.7909 - val_loss: 0.6269 - val_accuracy: 0.7888\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.6348 - accuracy: 0.1663 - val_loss: 2.0743 - val_accuracy: 0.3846\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.5733 - accuracy: 0.6073 - val_loss: 1.2219 - val_accuracy: 0.7444\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.0523 - accuracy: 0.7626 - val_loss: 0.8884 - val_accuracy: 0.8014\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7979 - accuracy: 0.8169 - val_loss: 0.7405 - val_accuracy: 0.8201\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6942 - accuracy: 0.8271 - val_loss: 0.6537 - val_accuracy: 0.8222\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6959 - accuracy: 0.7959 - val_loss: 0.5789 - val_accuracy: 0.8407\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5734 - accuracy: 0.8336 - val_loss: 0.5723 - val_accuracy: 0.8310\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5409 - accuracy: 0.8382 - val_loss: 0.5330 - val_accuracy: 0.8409\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.8436 - val_loss: 0.5256 - val_accuracy: 0.8347\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5396 - accuracy: 0.8249 - val_loss: 0.5323 - val_accuracy: 0.8278\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.8331 - val_loss: 0.5810 - val_accuracy: 0.8088\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5356 - accuracy: 0.8406 - val_loss: 0.4919 - val_accuracy: 0.8398\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4596 - accuracy: 0.8525 - val_loss: 0.5105 - val_accuracy: 0.8343\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4831 - accuracy: 0.8411 - val_loss: 0.4563 - val_accuracy: 0.8524\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4580 - accuracy: 0.8457 - val_loss: 0.4402 - val_accuracy: 0.8562\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4285 - accuracy: 0.8593 - val_loss: 0.4965 - val_accuracy: 0.8320\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4719 - accuracy: 0.8403 - val_loss: 0.4810 - val_accuracy: 0.8445\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4197 - accuracy: 0.8500 - val_loss: 0.4526 - val_accuracy: 0.8468\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4628 - accuracy: 0.8474 - val_loss: 0.4481 - val_accuracy: 0.8500\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4477 - accuracy: 0.8500 - val_loss: 0.4335 - val_accuracy: 0.8558\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4597 - accuracy: 0.8506 - val_loss: 0.4430 - val_accuracy: 0.8494\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.8318 - val_loss: 0.4625 - val_accuracy: 0.8419\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.8526 - val_loss: 0.3830 - val_accuracy: 0.8693\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4516 - accuracy: 0.8505 - val_loss: 0.4321 - val_accuracy: 0.8589\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3788 - accuracy: 0.8699 - val_loss: 0.4625 - val_accuracy: 0.8454\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4058 - accuracy: 0.8593 - val_loss: 0.4536 - val_accuracy: 0.8412\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4321 - accuracy: 0.8425 - val_loss: 0.4592 - val_accuracy: 0.8483\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8353 - val_loss: 0.4673 - val_accuracy: 0.8441\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4566 - accuracy: 0.8536 - val_loss: 0.4230 - val_accuracy: 0.8554\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4417 - accuracy: 0.8562 - val_loss: 0.4108 - val_accuracy: 0.8569\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4572 - accuracy: 0.8502 - val_loss: 0.4516 - val_accuracy: 0.8444\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4663 - accuracy: 0.8465 - val_loss: 0.4281 - val_accuracy: 0.8545\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5738 - accuracy: 0.8104 - val_loss: 0.4428 - val_accuracy: 0.8524\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4917 - accuracy: 0.8221 - val_loss: 0.4985 - val_accuracy: 0.8290\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4735 - accuracy: 0.8423 - val_loss: 0.4544 - val_accuracy: 0.8482\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.8393 - val_loss: 0.4629 - val_accuracy: 0.8480\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8571 - val_loss: 0.4299 - val_accuracy: 0.8590\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4531 - accuracy: 0.8468 - val_loss: 0.4133 - val_accuracy: 0.8627\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.8578 - val_loss: 0.3936 - val_accuracy: 0.8748\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4491 - accuracy: 0.8525 - val_loss: 0.4483 - val_accuracy: 0.8493\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4279 - accuracy: 0.8622 - val_loss: 0.4281 - val_accuracy: 0.8516\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3846 - accuracy: 0.8724 - val_loss: 0.4109 - val_accuracy: 0.8624\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4141 - accuracy: 0.8585 - val_loss: 0.4186 - val_accuracy: 0.8568\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3893 - accuracy: 0.8771 - val_loss: 0.4109 - val_accuracy: 0.8654\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3685 - accuracy: 0.8816 - val_loss: 0.4557 - val_accuracy: 0.8485\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3881 - accuracy: 0.8735 - val_loss: 0.4454 - val_accuracy: 0.8454\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4149 - accuracy: 0.8658 - val_loss: 0.4239 - val_accuracy: 0.8543\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.8519 - val_loss: 0.4280 - val_accuracy: 0.8616\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4970 - accuracy: 0.8350 - val_loss: 0.4465 - val_accuracy: 0.8560\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4233 - accuracy: 0.8633 - val_loss: 0.4062 - val_accuracy: 0.8651\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.2606 - accuracy: 0.2946 - val_loss: 1.6969 - val_accuracy: 0.5439\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.3617 - accuracy: 0.6887 - val_loss: 1.0532 - val_accuracy: 0.8046\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.9079 - accuracy: 0.8265 - val_loss: 0.7455 - val_accuracy: 0.8657\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.6179 - accuracy: 0.8873 - val_loss: 0.5577 - val_accuracy: 0.8811\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.8848 - val_loss: 0.4966 - val_accuracy: 0.8760\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.4371 - accuracy: 0.9022 - val_loss: 0.4093 - val_accuracy: 0.8984\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4063 - accuracy: 0.8964 - val_loss: 0.3910 - val_accuracy: 0.8943\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3325 - accuracy: 0.9115 - val_loss: 0.3456 - val_accuracy: 0.9055\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.3418 - accuracy: 0.9062 - val_loss: 0.3385 - val_accuracy: 0.9006\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3489 - accuracy: 0.8967 - val_loss: 0.3370 - val_accuracy: 0.8973\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.3062 - accuracy: 0.9013 - val_loss: 0.3492 - val_accuracy: 0.8917\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.3549 - accuracy: 0.8946 - val_loss: 0.3342 - val_accuracy: 0.8981\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2893 - accuracy: 0.9087 - val_loss: 0.3136 - val_accuracy: 0.9037\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2865 - accuracy: 0.9082 - val_loss: 0.2896 - val_accuracy: 0.9112\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3183 - accuracy: 0.8970 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2839 - accuracy: 0.9052 - val_loss: 0.3068 - val_accuracy: 0.9017\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2848 - accuracy: 0.9073 - val_loss: 0.2715 - val_accuracy: 0.9117\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2752 - accuracy: 0.9121 - val_loss: 0.2839 - val_accuracy: 0.9073\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2477 - accuracy: 0.9186 - val_loss: 0.2669 - val_accuracy: 0.9175\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2294 - accuracy: 0.9251 - val_loss: 0.2499 - val_accuracy: 0.9206\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2912 - accuracy: 0.9035 - val_loss: 0.2522 - val_accuracy: 0.9148\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2925 - accuracy: 0.9070 - val_loss: 0.2678 - val_accuracy: 0.9156\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.2764 - accuracy: 0.9118 - val_loss: 0.2289 - val_accuracy: 0.9253\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2244 - accuracy: 0.9272 - val_loss: 0.2402 - val_accuracy: 0.9244\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2481 - accuracy: 0.9245 - val_loss: 0.2644 - val_accuracy: 0.9106\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2263 - accuracy: 0.9282 - val_loss: 0.2548 - val_accuracy: 0.9126\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2783 - accuracy: 0.9019 - val_loss: 0.2787 - val_accuracy: 0.9100\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2773 - accuracy: 0.9051 - val_loss: 0.2644 - val_accuracy: 0.9115\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2586 - accuracy: 0.9129 - val_loss: 0.2691 - val_accuracy: 0.9077\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2780 - accuracy: 0.9082 - val_loss: 0.2316 - val_accuracy: 0.9238\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2898 - accuracy: 0.9039 - val_loss: 0.2937 - val_accuracy: 0.9058\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2601 - accuracy: 0.9098 - val_loss: 0.2629 - val_accuracy: 0.9162\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3160 - accuracy: 0.8923 - val_loss: 0.2614 - val_accuracy: 0.9114\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2889 - accuracy: 0.8992 - val_loss: 0.2777 - val_accuracy: 0.9126\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3063 - accuracy: 0.9012 - val_loss: 0.2827 - val_accuracy: 0.9060\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2755 - accuracy: 0.9038 - val_loss: 0.2656 - val_accuracy: 0.9144\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2335 - accuracy: 0.9243 - val_loss: 0.2662 - val_accuracy: 0.9132\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2882 - accuracy: 0.9026 - val_loss: 0.2404 - val_accuracy: 0.9225\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2869 - accuracy: 0.9077 - val_loss: 0.2207 - val_accuracy: 0.9312\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2630 - accuracy: 0.9135 - val_loss: 0.2687 - val_accuracy: 0.9150\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2671 - accuracy: 0.9196 - val_loss: 0.2366 - val_accuracy: 0.9222\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2216 - accuracy: 0.9302 - val_loss: 0.2505 - val_accuracy: 0.9143\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2556 - accuracy: 0.9114 - val_loss: 0.2370 - val_accuracy: 0.9176\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2310 - accuracy: 0.9199 - val_loss: 0.2389 - val_accuracy: 0.9211\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2111 - accuracy: 0.9296 - val_loss: 0.2563 - val_accuracy: 0.9160\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2414 - accuracy: 0.9205 - val_loss: 0.2647 - val_accuracy: 0.9091\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2480 - accuracy: 0.9165 - val_loss: 0.2253 - val_accuracy: 0.9243\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2616 - accuracy: 0.9146 - val_loss: 0.2499 - val_accuracy: 0.9147\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3054 - accuracy: 0.8921 - val_loss: 0.2345 - val_accuracy: 0.9245\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2421 - accuracy: 0.9226 - val_loss: 0.2403 - val_accuracy: 0.9210\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.3682 - accuracy: 0.2499 - val_loss: 1.7257 - val_accuracy: 0.5590\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.3290 - accuracy: 0.7451 - val_loss: 1.0038 - val_accuracy: 0.8337\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.8303 - accuracy: 0.8622 - val_loss: 0.6385 - val_accuracy: 0.9136\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5336 - accuracy: 0.9189 - val_loss: 0.4657 - val_accuracy: 0.9183\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4053 - accuracy: 0.9276 - val_loss: 0.3659 - val_accuracy: 0.9267\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.3477 - accuracy: 0.9234 - val_loss: 0.2956 - val_accuracy: 0.9438\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2972 - accuracy: 0.9316 - val_loss: 0.2867 - val_accuracy: 0.9310\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2483 - accuracy: 0.9408 - val_loss: 0.2434 - val_accuracy: 0.9420\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2439 - accuracy: 0.9342 - val_loss: 0.2265 - val_accuracy: 0.9410\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2413 - accuracy: 0.9309 - val_loss: 0.2363 - val_accuracy: 0.9354\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1880 - accuracy: 0.9489 - val_loss: 0.2280 - val_accuracy: 0.9319\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2224 - accuracy: 0.9358 - val_loss: 0.2008 - val_accuracy: 0.9432\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1837 - accuracy: 0.9446 - val_loss: 0.2065 - val_accuracy: 0.9392\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.9462 - val_loss: 0.1746 - val_accuracy: 0.9487\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2189 - accuracy: 0.9317 - val_loss: 0.1747 - val_accuracy: 0.9473\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1516 - accuracy: 0.9587 - val_loss: 0.1880 - val_accuracy: 0.9424\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1579 - accuracy: 0.9519 - val_loss: 0.1613 - val_accuracy: 0.9520\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1484 - accuracy: 0.9574 - val_loss: 0.1724 - val_accuracy: 0.9470\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1566 - accuracy: 0.9520 - val_loss: 0.1692 - val_accuracy: 0.9481\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.9471 - val_loss: 0.1519 - val_accuracy: 0.9529\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1713 - accuracy: 0.9473 - val_loss: 0.1548 - val_accuracy: 0.9526\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1539 - accuracy: 0.9556 - val_loss: 0.1615 - val_accuracy: 0.9490\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1621 - accuracy: 0.9471 - val_loss: 0.1378 - val_accuracy: 0.9559\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1500 - accuracy: 0.9498 - val_loss: 0.1472 - val_accuracy: 0.9556\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1484 - accuracy: 0.9548 - val_loss: 0.1606 - val_accuracy: 0.9506\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1470 - accuracy: 0.9497 - val_loss: 0.1546 - val_accuracy: 0.9460\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1631 - accuracy: 0.9449 - val_loss: 0.1636 - val_accuracy: 0.9451\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1488 - accuracy: 0.9494 - val_loss: 0.1591 - val_accuracy: 0.9453\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1779 - accuracy: 0.9419 - val_loss: 0.1657 - val_accuracy: 0.9466\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1907 - accuracy: 0.9395 - val_loss: 0.1392 - val_accuracy: 0.9546\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1805 - accuracy: 0.9441 - val_loss: 0.1524 - val_accuracy: 0.9496\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1460 - accuracy: 0.9459 - val_loss: 0.1525 - val_accuracy: 0.9498\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1921 - accuracy: 0.9361 - val_loss: 0.1562 - val_accuracy: 0.9469\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1675 - accuracy: 0.9451 - val_loss: 0.1755 - val_accuracy: 0.9414\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2074 - accuracy: 0.9298 - val_loss: 0.1661 - val_accuracy: 0.9426\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1380 - accuracy: 0.9511 - val_loss: 0.1617 - val_accuracy: 0.9483\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1354 - accuracy: 0.9559 - val_loss: 0.1451 - val_accuracy: 0.9540\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1431 - accuracy: 0.9536 - val_loss: 0.1464 - val_accuracy: 0.9515\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1722 - accuracy: 0.9459 - val_loss: 0.1292 - val_accuracy: 0.9579\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1577 - accuracy: 0.9509 - val_loss: 0.1664 - val_accuracy: 0.9444\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1530 - accuracy: 0.9467 - val_loss: 0.1336 - val_accuracy: 0.9561\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1419 - accuracy: 0.9528 - val_loss: 0.1443 - val_accuracy: 0.9524\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1403 - accuracy: 0.9566 - val_loss: 0.1363 - val_accuracy: 0.9540\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1227 - accuracy: 0.9575 - val_loss: 0.1580 - val_accuracy: 0.9470\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1118 - accuracy: 0.9607 - val_loss: 0.1681 - val_accuracy: 0.9429\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1416 - accuracy: 0.9538 - val_loss: 0.1489 - val_accuracy: 0.9510\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1123 - accuracy: 0.9652 - val_loss: 0.1448 - val_accuracy: 0.9513\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1672 - accuracy: 0.9487 - val_loss: 0.1395 - val_accuracy: 0.9523\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1803 - accuracy: 0.9421 - val_loss: 0.1493 - val_accuracy: 0.9513\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1538 - accuracy: 0.9508 - val_loss: 0.1279 - val_accuracy: 0.9561\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.2027 - accuracy: 0.3525 - val_loss: 1.6097 - val_accuracy: 0.6083\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.1673 - accuracy: 0.7843 - val_loss: 0.8363 - val_accuracy: 0.9016\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6573 - accuracy: 0.9149 - val_loss: 0.4766 - val_accuracy: 0.9509\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3739 - accuracy: 0.9622 - val_loss: 0.3382 - val_accuracy: 0.9458\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2999 - accuracy: 0.9488 - val_loss: 0.2531 - val_accuracy: 0.9603\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2536 - accuracy: 0.9548 - val_loss: 0.2042 - val_accuracy: 0.9643\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1858 - accuracy: 0.9653 - val_loss: 0.1854 - val_accuracy: 0.9625\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1597 - accuracy: 0.9709 - val_loss: 0.1592 - val_accuracy: 0.9644\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1641 - accuracy: 0.9604 - val_loss: 0.1476 - val_accuracy: 0.9666\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1647 - accuracy: 0.9564 - val_loss: 0.1535 - val_accuracy: 0.9618\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1340 - accuracy: 0.9619 - val_loss: 0.1550 - val_accuracy: 0.9585\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1308 - accuracy: 0.9701 - val_loss: 0.1426 - val_accuracy: 0.9619\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.9679 - val_loss: 0.1313 - val_accuracy: 0.9640\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0874 - accuracy: 0.9788 - val_loss: 0.1061 - val_accuracy: 0.9722\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1209 - accuracy: 0.9690 - val_loss: 0.1098 - val_accuracy: 0.9717\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1074 - accuracy: 0.9687 - val_loss: 0.1202 - val_accuracy: 0.9623\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0998 - accuracy: 0.9667 - val_loss: 0.0979 - val_accuracy: 0.9736\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0971 - accuracy: 0.9751 - val_loss: 0.1010 - val_accuracy: 0.9725\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0980 - accuracy: 0.9663 - val_loss: 0.1030 - val_accuracy: 0.9699\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0912 - accuracy: 0.9744 - val_loss: 0.0914 - val_accuracy: 0.9732\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1207 - accuracy: 0.9612 - val_loss: 0.0942 - val_accuracy: 0.9724\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1089 - accuracy: 0.9657 - val_loss: 0.0927 - val_accuracy: 0.9727\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0895 - accuracy: 0.9725 - val_loss: 0.0769 - val_accuracy: 0.9769\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0878 - accuracy: 0.9721 - val_loss: 0.0837 - val_accuracy: 0.9769\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1013 - accuracy: 0.9684 - val_loss: 0.0986 - val_accuracy: 0.9692\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0757 - accuracy: 0.9791 - val_loss: 0.0806 - val_accuracy: 0.9746\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0989 - accuracy: 0.9673 - val_loss: 0.0896 - val_accuracy: 0.9710\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0873 - accuracy: 0.9739 - val_loss: 0.0925 - val_accuracy: 0.9709\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1030 - accuracy: 0.9675 - val_loss: 0.1100 - val_accuracy: 0.9645\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0903 - accuracy: 0.9710 - val_loss: 0.0757 - val_accuracy: 0.9764\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1178 - accuracy: 0.9617 - val_loss: 0.0961 - val_accuracy: 0.9689\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0738 - accuracy: 0.9763 - val_loss: 0.0801 - val_accuracy: 0.9733\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1362 - accuracy: 0.9576 - val_loss: 0.0896 - val_accuracy: 0.9723\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1027 - accuracy: 0.9681 - val_loss: 0.0919 - val_accuracy: 0.9699\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1638 - accuracy: 0.9524 - val_loss: 0.0935 - val_accuracy: 0.9690\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0770 - accuracy: 0.9778 - val_loss: 0.0895 - val_accuracy: 0.9741\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0734 - accuracy: 0.9772 - val_loss: 0.0840 - val_accuracy: 0.9739\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0950 - accuracy: 0.9666 - val_loss: 0.0722 - val_accuracy: 0.9763\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1207 - accuracy: 0.9581 - val_loss: 0.0789 - val_accuracy: 0.9753\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0811 - accuracy: 0.9743 - val_loss: 0.0790 - val_accuracy: 0.9742\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0880 - accuracy: 0.9691 - val_loss: 0.0717 - val_accuracy: 0.9776\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0732 - accuracy: 0.9784 - val_loss: 0.0699 - val_accuracy: 0.9771\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0775 - accuracy: 0.9756 - val_loss: 0.0655 - val_accuracy: 0.9789\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0684 - accuracy: 0.9768 - val_loss: 0.0696 - val_accuracy: 0.9790\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0720 - accuracy: 0.9784 - val_loss: 0.1046 - val_accuracy: 0.9656\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.0855 - val_accuracy: 0.9728\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0692 - accuracy: 0.9772 - val_loss: 0.0685 - val_accuracy: 0.9777\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 0.0793 - val_accuracy: 0.9734\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0953 - accuracy: 0.9656 - val_loss: 0.0708 - val_accuracy: 0.9756\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0866 - accuracy: 0.9723 - val_loss: 0.0626 - val_accuracy: 0.9803\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.2108 - accuracy: 0.3118 - val_loss: 1.5624 - val_accuracy: 0.6168\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.1705 - accuracy: 0.7868 - val_loss: 0.8665 - val_accuracy: 0.8890\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6566 - accuracy: 0.9368 - val_loss: 0.4644 - val_accuracy: 0.9754\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.3485 - accuracy: 0.9831 - val_loss: 0.2778 - val_accuracy: 0.9774\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2362 - accuracy: 0.9847 - val_loss: 0.1986 - val_accuracy: 0.9831\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1830 - accuracy: 0.9791 - val_loss: 0.1453 - val_accuracy: 0.9867\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1371 - accuracy: 0.9833 - val_loss: 0.1238 - val_accuracy: 0.9850\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1122 - accuracy: 0.9859 - val_loss: 0.1084 - val_accuracy: 0.9845\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0960 - accuracy: 0.9861 - val_loss: 0.0917 - val_accuracy: 0.9864\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0924 - accuracy: 0.9849 - val_loss: 0.0851 - val_accuracy: 0.9866\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0746 - accuracy: 0.9849 - val_loss: 0.0963 - val_accuracy: 0.9778\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0747 - accuracy: 0.9871 - val_loss: 0.0763 - val_accuracy: 0.9842\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9919 - val_loss: 0.0657 - val_accuracy: 0.9874\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9925 - val_loss: 0.0572 - val_accuracy: 0.9879\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0680 - accuracy: 0.9809 - val_loss: 0.0507 - val_accuracy: 0.9903\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0435 - accuracy: 0.9926 - val_loss: 0.0639 - val_accuracy: 0.9837\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0514 - accuracy: 0.9866 - val_loss: 0.0457 - val_accuracy: 0.9928\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0403 - accuracy: 0.9919 - val_loss: 0.0481 - val_accuracy: 0.9889\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9902 - val_loss: 0.0412 - val_accuracy: 0.9899\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.0392 - val_accuracy: 0.9916\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0479 - accuracy: 0.9874 - val_loss: 0.0405 - val_accuracy: 0.9895\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0447 - accuracy: 0.9884 - val_loss: 0.0450 - val_accuracy: 0.9892\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9877 - val_loss: 0.0344 - val_accuracy: 0.9925\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9894 - val_loss: 0.0332 - val_accuracy: 0.9920\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9865 - val_loss: 0.0438 - val_accuracy: 0.9883\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9917 - val_loss: 0.0356 - val_accuracy: 0.9908\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9906 - val_loss: 0.0356 - val_accuracy: 0.9916\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9886 - val_loss: 0.0385 - val_accuracy: 0.9890\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.0363 - val_accuracy: 0.9896\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0379 - accuracy: 0.9909 - val_loss: 0.0249 - val_accuracy: 0.9948\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.0412 - val_accuracy: 0.9880\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.0334 - val_accuracy: 0.9915\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0672 - accuracy: 0.9777 - val_loss: 0.0354 - val_accuracy: 0.9890\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.0403 - val_accuracy: 0.9887\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0618 - accuracy: 0.9833 - val_loss: 0.0400 - val_accuracy: 0.9869\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0350 - accuracy: 0.9899 - val_loss: 0.0362 - val_accuracy: 0.9912\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.0373 - val_accuracy: 0.9908\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9921 - val_loss: 0.0273 - val_accuracy: 0.9913\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9909 - val_loss: 0.0269 - val_accuracy: 0.9918\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.0408 - val_accuracy: 0.9874\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 0.0275 - val_accuracy: 0.9909\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0234 - val_accuracy: 0.9940\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 0.0221 - val_accuracy: 0.9939\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0276 - val_accuracy: 0.9924\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.0346 - val_accuracy: 0.9895\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 0.0356 - val_accuracy: 0.9878\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.0260 - val_accuracy: 0.9923\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0284 - val_accuracy: 0.9910\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9848 - val_loss: 0.0352 - val_accuracy: 0.9893\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0266 - val_accuracy: 0.9923\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.9894 - accuracy: 0.4891 - val_loss: 1.3450 - val_accuracy: 0.7850\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.9614 - accuracy: 0.9022 - val_loss: 0.6652 - val_accuracy: 0.9685\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.9695 - val_loss: 0.3452 - val_accuracy: 0.9909\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2476 - accuracy: 0.9947 - val_loss: 0.2037 - val_accuracy: 0.9890\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1599 - accuracy: 0.9936 - val_loss: 0.1350 - val_accuracy: 0.9921\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1142 - accuracy: 0.9942 - val_loss: 0.0901 - val_accuracy: 0.9973\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0868 - accuracy: 0.9943 - val_loss: 0.0796 - val_accuracy: 0.9934\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 0.9980 - val_loss: 0.0571 - val_accuracy: 0.9961\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0556 - accuracy: 0.9964 - val_loss: 0.0548 - val_accuracy: 0.9958\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0490 - accuracy: 0.9960 - val_loss: 0.0490 - val_accuracy: 0.9960\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0464 - accuracy: 0.9934 - val_loss: 0.0502 - val_accuracy: 0.9929\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0456 - accuracy: 0.9912 - val_loss: 0.0367 - val_accuracy: 0.9960\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0340 - accuracy: 0.9964 - val_loss: 0.0355 - val_accuracy: 0.9942\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9971 - val_loss: 0.0291 - val_accuracy: 0.9957\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9961 - val_loss: 0.0251 - val_accuracy: 0.9967\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0182 - accuracy: 0.9998 - val_loss: 0.0300 - val_accuracy: 0.9952\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9984 - val_loss: 0.0250 - val_accuracy: 0.9965\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0191 - accuracy: 0.9985 - val_loss: 0.0236 - val_accuracy: 0.9955\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 0.9986 - val_loss: 0.0249 - val_accuracy: 0.9947\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0190 - accuracy: 0.9973 - val_loss: 0.0185 - val_accuracy: 0.9963\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0263 - accuracy: 0.9952 - val_loss: 0.0203 - val_accuracy: 0.9962\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.0198 - val_accuracy: 0.9955\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9986 - val_loss: 0.0127 - val_accuracy: 0.9984\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.0174 - val_accuracy: 0.9965\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0159 - val_accuracy: 0.9973\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.0136 - val_accuracy: 0.9986\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.0163 - val_accuracy: 0.9954\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9977 - val_loss: 0.0186 - val_accuracy: 0.9958\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.0115 - val_accuracy: 0.9977\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9967 - val_loss: 0.0108 - val_accuracy: 0.9980\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.0133 - val_accuracy: 0.9969\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.9988 - val_loss: 0.0101 - val_accuracy: 0.9979\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9901 - val_loss: 0.0214 - val_accuracy: 0.9937\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.0131 - val_accuracy: 0.9971\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0166 - val_accuracy: 0.9955\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0112 - val_accuracy: 0.9973\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0154 - val_accuracy: 0.9953\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0121 - val_accuracy: 0.9972\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0129 - val_accuracy: 0.9970\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0087 - val_accuracy: 0.9986\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 0.9983\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0118 - val_accuracy: 0.9960\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0136 - val_accuracy: 0.9965\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0220 - accuracy: 0.9907 - val_loss: 0.0185 - val_accuracy: 0.9948\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.0104 - val_accuracy: 0.9970\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0116 - val_accuracy: 0.9958\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.0731 - accuracy: 0.4779 - val_loss: 1.4089 - val_accuracy: 0.7935\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.9477 - accuracy: 0.9163 - val_loss: 0.5906 - val_accuracy: 0.9769\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.9833 - val_loss: 0.2709 - val_accuracy: 0.9945\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1924 - accuracy: 0.9998 - val_loss: 0.1511 - val_accuracy: 0.9963\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1223 - accuracy: 0.9947 - val_loss: 0.0965 - val_accuracy: 0.9984\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9995 - val_loss: 0.0646 - val_accuracy: 0.9992\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0576 - accuracy: 0.9967 - val_loss: 0.0533 - val_accuracy: 0.9975\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0462 - accuracy: 0.9974 - val_loss: 0.0372 - val_accuracy: 0.9987\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9981 - val_loss: 0.0336 - val_accuracy: 0.9984\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0293 - accuracy: 0.9991 - val_loss: 0.0311 - val_accuracy: 0.9982\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0273 - accuracy: 0.9981 - val_loss: 0.0275 - val_accuracy: 0.9983\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9983 - val_loss: 0.0215 - val_accuracy: 0.9982\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9988\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9985\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 0.0124 - val_accuracy: 0.9995\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9996\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 0.9995\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 0.9995 - val_loss: 0.0120 - val_accuracy: 0.9982\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 0.0115 - val_accuracy: 0.9981\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 0.9988 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.0082 - val_accuracy: 0.9989\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0088 - val_accuracy: 0.9991\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.0058 - val_accuracy: 0.9998\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9989\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0072 - val_accuracy: 0.9991\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.0049 - val_accuracy: 0.9995\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0048 - val_accuracy: 0.9998\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0047 - val_accuracy: 0.9996\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 0.9986 - val_loss: 0.0076 - val_accuracy: 0.9989\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9988\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0037 - val_accuracy: 0.9996\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0031 - val_accuracy: 0.9998\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9998\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.0032 - val_accuracy: 0.9997\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.0652 - accuracy: 0.4834 - val_loss: 1.3004 - val_accuracy: 0.8753\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.8339 - accuracy: 0.9656 - val_loss: 0.4863 - val_accuracy: 0.9964\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3353 - accuracy: 0.9987 - val_loss: 0.2135 - val_accuracy: 0.9985\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9997\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0960 - accuracy: 0.9990 - val_loss: 0.0738 - val_accuracy: 0.9997\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0643 - accuracy: 0.9982 - val_loss: 0.0506 - val_accuracy: 0.9995\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0446 - accuracy: 0.9989 - val_loss: 0.0407 - val_accuracy: 0.9995\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9999\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9971 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9997\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9998\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9982 - val_loss: 0.0177 - val_accuracy: 0.9992\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9995\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9999\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9995\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9999 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9994\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9997\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 0.9999\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9998\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9998\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9999\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9997\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9999\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0065 - val_accuracy: 0.9982\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 9.6109e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 8.4577e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9998\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 8.1238e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9997\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 8.9436e-04 - accuracy: 1.0000 - val_loss: 8.1812e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9999\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.0083 - accuracy: 0.4909 - val_loss: 1.2398 - val_accuracy: 0.9401\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7792 - accuracy: 0.9913 - val_loss: 0.4505 - val_accuracy: 0.9994\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2997 - accuracy: 0.9993 - val_loss: 0.1938 - val_accuracy: 0.9998\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1328 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9996\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9999\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9997\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9998\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9998\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9999\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 8.5976e-04 - accuracy: 1.0000 - val_loss: 9.0316e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 7.8730e-04 - accuracy: 1.0000 - val_loss: 8.9628e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0019 - val_accuracy: 0.9999\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 9.6943e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 6.7241e-04 - accuracy: 1.0000 - val_loss: 6.0500e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 6.9901e-04 - accuracy: 1.0000 - val_loss: 6.6912e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 6.7599e-04 - accuracy: 1.0000 - val_loss: 7.3366e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 9.4491e-04 - val_accuracy: 0.9999\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 5.4950e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 5.2500e-04 - accuracy: 1.0000 - val_loss: 4.0991e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 4.0312e-04 - accuracy: 1.0000 - val_loss: 3.7066e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.9253e-04 - accuracy: 1.0000 - val_loss: 4.7832e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 4.1404e-04 - accuracy: 1.0000 - val_loss: 4.3373e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 3.2371e-04 - accuracy: 1.0000 - val_loss: 2.9940e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.6350e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 3.6782e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 8.2911e-04 - val_accuracy: 1.0000\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.9749 - accuracy: 0.5023 - val_loss: 1.2148 - val_accuracy: 0.8981\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7583 - accuracy: 0.9836 - val_loss: 0.4277 - val_accuracy: 0.9994\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2698 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9998\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.1157 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9999\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.8342e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 8.5580e-04 - accuracy: 1.0000 - val_loss: 9.3062e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 8.7346e-04 - accuracy: 1.0000 - val_loss: 7.5747e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 9.0815e-04 - accuracy: 1.0000 - val_loss: 8.2917e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 6.3121e-04 - accuracy: 1.0000 - val_loss: 6.4354e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 9.8495e-04 - accuracy: 1.0000 - val_loss: 6.8537e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 4.8612e-04 - accuracy: 1.0000 - val_loss: 5.5102e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 5.7353e-04 - accuracy: 1.0000 - val_loss: 5.4325e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 4.4885e-04 - accuracy: 1.0000 - val_loss: 4.5798e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 3.8315e-04 - accuracy: 1.0000 - val_loss: 3.4375e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 4.2649e-04 - accuracy: 1.0000 - val_loss: 6.0491e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 5.2382e-04 - accuracy: 1.0000 - val_loss: 2.8444e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.8671e-04 - accuracy: 1.0000 - val_loss: 2.6306e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.5344e-04 - accuracy: 1.0000 - val_loss: 2.3223e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.3858e-04 - accuracy: 1.0000 - val_loss: 2.7085e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.1354e-04 - accuracy: 1.0000 - val_loss: 3.1616e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 3.2808e-04 - accuracy: 1.0000 - val_loss: 2.8824e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.9316e-04 - accuracy: 1.0000 - val_loss: 1.9566e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 2.2251e-04 - accuracy: 1.0000 - val_loss: 2.1836e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.6255e-04 - accuracy: 1.0000 - val_loss: 1.9338e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 4.9141e-04 - accuracy: 1.0000 - val_loss: 2.5432e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfl39is0rQYX",
        "colab_type": "code",
        "outputId": "5ee21002-2aed-44d8-ed1b-e205382dc59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "plot_bler_vs_ebno(blers, snr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1X8K5XgTenj",
        "colab_type": "code",
        "outputId": "34119b2c-27e1-451c-ac4e-39b14f2326a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "blers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20974,\n",
              " 0.13531,\n",
              " 0.07759,\n",
              " 0.04569,\n",
              " 0.02518,\n",
              " 0.00706,\n",
              " 0.00254,\n",
              " 0.00074,\n",
              " 0.00019,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYCXKSIe1WH",
        "colab_type": "text"
      },
      "source": [
        "# Constellation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lA8qx1zeY7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "def constellation(model, test):\n",
        "  cps = model.predict(test)\n",
        "  if cps.shape[1] == 2:\n",
        "    x, y = zip(*cps)\n",
        "  else:\n",
        "    tsne = TSNE(n_components=2, perplexity=15, learning_rate=100, early_exaggeration=10, n_iter=700)\n",
        "    tsne_results = tsne.fit_transform(cps)\n",
        "    x, y = zip(*tsne_results)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def plot_constellation(x, y):\n",
        "  fig, ax = plt.subplots(figsize=(6,6))\n",
        "  ax.scatter(x, y, color='k', s=0.5)\n",
        "  #ax.set_xlim(-2,2)\n",
        "  #ax.set_ylim(-2,2)\n",
        "  ax.grid()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMlq8FMCtpvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Eb_No_tr = 10**(7/10)\n",
        "std = math.sqrt(1/(2 * R * Eb_No_tr))\n",
        "ae, encoder = autoencoder(M, n, std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfNYsI-Il_Dd",
        "colab_type": "code",
        "outputId": "39ee986f-c5fb-4560-9029-7cdbe1ebd977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = ae.fit(x_train, x_train, epochs = 50, batch_size = 100, shuffle = True, validation_data = (x_val, x_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 2.3740 - accuracy: 0.2925 - val_loss: 1.9959 - val_accuracy: 0.4321\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.7264 - accuracy: 0.5131 - val_loss: 1.5150 - val_accuracy: 0.5539\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 1.3511 - accuracy: 0.5820 - val_loss: 1.2206 - val_accuracy: 0.5854\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 1.1187 - accuracy: 0.6288 - val_loss: 1.0409 - val_accuracy: 0.6795\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.9654 - accuracy: 0.6898 - val_loss: 0.9017 - val_accuracy: 0.6960\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.8415 - accuracy: 0.7517 - val_loss: 0.8057 - val_accuracy: 0.7637\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.7604 - accuracy: 0.7922 - val_loss: 0.7026 - val_accuracy: 0.8223\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.6623 - accuracy: 0.8476 - val_loss: 0.6556 - val_accuracy: 0.8404\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5981 - accuracy: 0.8531 - val_loss: 0.5732 - val_accuracy: 0.8822\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.5624 - accuracy: 0.8606 - val_loss: 0.5158 - val_accuracy: 0.8846\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.8949 - val_loss: 0.4670 - val_accuracy: 0.8962\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.8914 - val_loss: 0.4312 - val_accuracy: 0.9062\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.4317 - accuracy: 0.8941 - val_loss: 0.3849 - val_accuracy: 0.9229\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3707 - accuracy: 0.9268 - val_loss: 0.3677 - val_accuracy: 0.9218\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.9185 - val_loss: 0.3781 - val_accuracy: 0.9053\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3289 - accuracy: 0.9250 - val_loss: 0.3075 - val_accuracy: 0.9325\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3484 - accuracy: 0.9055 - val_loss: 0.3003 - val_accuracy: 0.9262\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2891 - accuracy: 0.9311 - val_loss: 0.3250 - val_accuracy: 0.9101\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.3275 - accuracy: 0.9069 - val_loss: 0.3131 - val_accuracy: 0.9164\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2673 - accuracy: 0.9329 - val_loss: 0.2971 - val_accuracy: 0.9119\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2548 - accuracy: 0.9384 - val_loss: 0.2634 - val_accuracy: 0.9315\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2307 - accuracy: 0.9438 - val_loss: 0.2602 - val_accuracy: 0.9287\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2523 - accuracy: 0.9293 - val_loss: 0.2499 - val_accuracy: 0.9220\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2786 - accuracy: 0.9146 - val_loss: 0.2713 - val_accuracy: 0.9211\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2279 - accuracy: 0.9369 - val_loss: 0.2315 - val_accuracy: 0.9428\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2946 - accuracy: 0.9149 - val_loss: 0.2648 - val_accuracy: 0.9158\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2154 - accuracy: 0.9358 - val_loss: 0.2239 - val_accuracy: 0.9320\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2104 - accuracy: 0.9441 - val_loss: 0.2801 - val_accuracy: 0.9123\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2265 - accuracy: 0.9351 - val_loss: 0.2543 - val_accuracy: 0.9135\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2295 - accuracy: 0.9257 - val_loss: 0.2233 - val_accuracy: 0.9316\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2000 - accuracy: 0.9365 - val_loss: 0.2071 - val_accuracy: 0.9341\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2972 - accuracy: 0.8951 - val_loss: 0.2165 - val_accuracy: 0.9393\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1879 - accuracy: 0.9399 - val_loss: 0.2026 - val_accuracy: 0.9326\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2289 - accuracy: 0.9243 - val_loss: 0.2100 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2756 - accuracy: 0.9023 - val_loss: 0.1993 - val_accuracy: 0.9404\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2580 - accuracy: 0.9044 - val_loss: 0.2102 - val_accuracy: 0.9382\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1683 - accuracy: 0.9482 - val_loss: 0.1944 - val_accuracy: 0.9407\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2101 - accuracy: 0.9339 - val_loss: 0.2029 - val_accuracy: 0.9367\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2412 - accuracy: 0.9117 - val_loss: 0.2337 - val_accuracy: 0.9218\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1644 - accuracy: 0.9586 - val_loss: 0.2201 - val_accuracy: 0.9261\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1548 - accuracy: 0.9576 - val_loss: 0.1794 - val_accuracy: 0.9452\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2410 - accuracy: 0.9166 - val_loss: 0.2241 - val_accuracy: 0.9243\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2158 - accuracy: 0.9279 - val_loss: 0.2280 - val_accuracy: 0.9245\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1869 - accuracy: 0.9521 - val_loss: 0.2017 - val_accuracy: 0.9346\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2718 - accuracy: 0.9117 - val_loss: 0.2685 - val_accuracy: 0.9018\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2599 - accuracy: 0.8874 - val_loss: 0.2274 - val_accuracy: 0.9176\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1989 - accuracy: 0.9370 - val_loss: 0.1992 - val_accuracy: 0.9327\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1538 - accuracy: 0.9511 - val_loss: 0.1854 - val_accuracy: 0.9376\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1872 - accuracy: 0.9391 - val_loss: 0.1976 - val_accuracy: 0.9340\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1979 - accuracy: 0.9255 - val_loss: 0.2041 - val_accuracy: 0.9232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biLmOeg4_0au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = constellation(encoder, x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUsTfdtlGr6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minix = min(x)\n",
        "maxix = max(x)\n",
        "miniy = min(y)\n",
        "maxiy = max(y)\n",
        "k = [2*(xi - minix)/(maxix-minix) for xi in x]\n",
        "l = [2*(xi - miniy)/(maxiy-miniy) for xi in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-sCECCXqxGo",
        "colab_type": "code",
        "outputId": "8bb33116-cfd5-4048-f4be-2a30df4d3a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "plot_constellation(x, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAFlCAYAAADh1fPjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfXQU5f028OsLuhLY+BLUJELCSwMqcmokQC1BIahdaqUWAhFbW5VaXrScB1s1VeE57ZNYyaPnZ/G0gi+FB1trEAJCrBiUX1BAlBgFrQlIwBIDCfxKPJoVDiv1fv7IZpvN7ia72dm9Z++9Pufs2Z3ZyeZi2Fy5MzM7I0opEBGRefroDkBERLHBgiciMhQLnojIUCx4IiJDseCJiAzFgiciMtRZOr7phRdeqIYOHQoA+OqrrzBgwAAdMcLGjNZJhJzMaA1mtEbnjLW1tf9SSl0U9hcrpeJ+y8vLUx2qq6uV3TGjdRIhJzNagxmt0TkjgPdUBF3LTTRERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8kSYejweVlZXweDy6o5ChWPBEmlRVVaGwsBBVVVW6o5ChWPBEmrhcLlRUVMDlcumOQoZiwRMRGYoFT6QJN9FQrLHgiTThJhqKNS2X7CMiwOFwYNq0abpjkME4gifSwO12Y8mSJXC73bqjkME4gifS4JFHHsHSpUtx5swZPProo7rjkKE4gifSIDc3F3369EFubq7uKGQwFjxRnLW0tGDZsmVYuXIlpk+frjsOGSzqTTQikgXgeQDpABSAZ5RSy6J9XSJTTZ06FXv37sXJkydx++23645DBrNiG/wZAL9WSr0vIqkAakXkdaVUnQWvTWScTz/91O+eKFai3kSjlGpWSr3vfdwGoB7AoGhfl8hUIuJ3TxQropSy7sVEhgJ4C8BopdSXXZ6bC2AuAKSnp+eVl5cDaD9czOl0WpYhFpjROomQM9YZa2trfY/z8vJ69Rpcj9ZItIwFBQW1SqmxYX+xUsqSGwAngFoAM3paNi8vT3Worq5WdseM1kmEnLHM2NbWptC+r0q1//j1TrKvR6skWkYA76kIetmSo2hE5GwAFQBeUEqtt+I1iUw0efJk3+PBgwfrC0JJIeqCl/YNiX8GUK+U+q/oIxGZq/PmmZ07d2pMQsnAihF8PoCfApgiInu8txsteF0io2VnZ+uOQIaL+jBJpdQOADwcgIjIZvhJViIiQ7HgieKEO1Up3ljwRHFy5MgR3REoybDgiTS48847dUegJMCCJ9Jg5cqVuiNQEmDBExEZigVPRGQoFjxRHPDMkaQDC56IyFAseKI4UxaeopuoOyx4IiJDseCJiAzFgqdueTweVFZWwuPx6I6SsLiDlXRhwVO3qqqqUFhYiKqqKt1RiChCLHjqlsvlwqpVq7B69Wq0trbqjkNEEYj6fPBkNofDgU2bNqGiogJ9+/bFmjVrdEdKaDyChuKJBU89Wr58ud89ESUGbqKhHqWlpWHNmjVwOBxYsmQJ3G637khEFAaO4ClsjzzyCJYuXYozZ87g0Ucf1R0nIfAIGtKJI3gK2+jRowEAFRUVaGlp0ZyGiHrCgqewpaSkAAAOHDiAgoICzWkST1ZWlu4IlGRY8BS2m266yfd43759PGwyQo2NjbojUJJhwVPYHA4H1q1b55u+7rrrNKYhop6w4CkihYWFvsd79uzBpk2bNKaxN+6nIN1Y8BSx3Nxc3+Obb75ZYxJ747oh3VjwFLGtW7f6TY8fP15TEnv75ptvfI//8pe/aExCyYoFTxFLS0vzm66pqdGUxN4qKysxceJENDc347bbbtMdh5IQC5565dlnn/Wb7t+/v6Yk9pWRkYHt27cjIyNDdxRKUix46pW77rrLb/rUqVOakhBRKCx46rVt27b5TfNj+UT2woKnXps0aZLuCETUDRY8RcXhcPhNcxRPseZ2u3lW0zCx4Ckqp0+f1h2BkkxZWRlKS0tRVlamO4rt8XTBZDkR4ZWLKGaKi4v97ik0juApaixzigePx4PKyko4HA6UlJTA6XTqjmR7LHiKCW6LJ6u0tLQgPz8fxcXFmDFjBqqqqnRHShjcREOWUEqx1Ckmbr75ZuzevRu7du3Cww8/DJfLpTtSwuAInmKGhU/RcLvduOeee7Bnzx4AwLhx47BkyZKAI7coNI7gyTIcxZNV6urqMGbMGN9RWikpKdi8eTPLPUIcwVNM8TwsFKlNmzbhiiuu8JV7nz598OGHHwac5I56xoInS3U9oubYsWOaklAiWrFiRcB59D/99FPk5ORoSpTYWPAUc0VFRbojUALIzc3FggUL/OatW7cO2dnZmhIlPhY8Wa7rKH7t2rWaklCiuPrqq7F3716/eatWrfK7RCRFjjtZiUirrKwsNDU1+c379a9/jTvuuENPIINwBE8x0XUU/73vfU9TErIzEQko93nz5uHxxx/XlMgsLHiKmc4fJX/99dc1JiE7CnZI7Q033IAVK1ZoSGOmpCn41tZW3HLLLWhtbdUdJWm0tbX5TW/atElTErKbYOV+5ZVXYsuWLRrSmCtpCn7BggV46aWXAvbSU2yNHDnS97jr4W+UnIKV+7Bhw3yfWCXrJE3BL1++HEVFRVi2bBkqKyvh8Xh0R0oKtbW1GDx4MABgwoQJmtOQbsHKPSMjA4cOHdKQxnxJU/BpaWlYs2YNampqUFhYyDPSxYnT6cTevXtRVFSEyspK3XFIo1CnsWhubo5zkuSRNAXfweVyoaKiAi6Xi5f+ipOOX678qHnyClbuKSkpvJZAjCXdcfAOhwPTpk0DAJSUlKC0tBQejwcOhwPFxcW8iACRxUKN3E+ePBnnJMkn6UbwnRUXF2Px4sUAgNLSUmRmZuKZZ57h9nkii4Qqd47c4yOpC97pdKKkpARLlixBamoq3G435s2bh379+iErKwuNjY26IxIlrNra2qDzWe7xk9QF38HpdOL9999Hv379ALS/AZuamjBkyBB+6IKoFzhytwcWvFdOTg6OHDmCKVOm+M1fsGABamtr8cYbb2hKRpRYWO72wYLvJC0tDVu3bsXu3bsDnrvhhhswevRoDamIEkeo49xZ7nqw4IMYN24cDhw4gNTUVL/5H3/8MUQEM2bM0JSMyL4uu+yygHkul4vHuWvEgg8hJycHX375JX72s58FPLdhwwZee5Sok9GjR2P//v1+8y6++GK89tprmhIRwILv0erVqzFs2LCgz4kIhg4dGt9ARDbT0NCAjz/+2G/etm3bkJWVpSkRdWDBhyEtLQ1KKfzgBz8IeO7w4cMQEdxzzz0akhHp1draim9/+9u+6QsvvBBKKUyaNEljKurAgo/AK6+8EjBS6fDUU09xsw0lnQULFuDUqVM455xzcPfdd+PTTz/VHYk6seRUBSKyEsBNAI4rpYw+1GTUqFFQSqF///44depUwPMiggsuuIDnnaeksHz5ct89zzVkP1aN4P8fgKkWvVZCOHnyZMhDvz7//HOO5ikp8ERy9mZJwSul3gKQlEPW7o7vFREWPRFpI1Z9AEFEhgJ4JdQmGhGZC2AuAKSnp+eVl5cDANxut+3P4BhuxlDn3gCAvLw8KyMFSIT1CCRGTma0BjNao3PGgoKCWqXU2LC/WCllyQ3AUAD/CGfZvLw81aG6ulrZXSQZAXR7s0NGnRIhpxUZDx8+rC6//HJ1+PDh6AMFkSzrMdYSLSOA91QEvcyjaCym/vMLLyhuskkOkydPRn19PSZPnqw7CiUxFnyMKKV81yLtSkSQkZER50QUT8ePH/e7J9LBkoIXkRcB7AJwqYg0icjPrXjdRPfZZ5+FHM0fO3YM5557Li8XaKgtW7bA4XBgy5YtuqNQErPqKJpblVKZSqmzlVKDlVJ/tuJ1TaGUCnrCpba2NqSmpmLp0qUaUlGs1NTUYNKkSfB4PNi8ebPuOJTEuIkmTjpOmXrppZcGPPfggw9i/vz5HM0bYvz48Thz5gyA9stCEunCgo+zffv2QSmFn/zkJ37zn376aZSVlWlKRbFi90PwyGwseE3++te/4vDhwxg+fDhSU1Mxb948jvYMMHPmTN0RiHwsORcN9U52djYOHjyoOwZZqKKiQncEIh+O4Ili5Pzzz9cdgZIcC54oRj7//HPdESjJseCJLMJPKZPdsOCJiAzFgiciMhQLnigGujvhHFG8sOCJLMDt72RHLHgiIkOx4IksNnz4cN0RiACw4ImiVldX5zfNTyeTXbDgiaI0dmz4l8gkiicWPFGUTp065Xucn5+vMQmRPxY8UZSuu+463/2OHTs0pyH6DxY8UZRefvllLF68GC+//LLuKER+eLpgoig5nU6UlJTojkEUgCN4IiJDseCJiAzFgiciMhQLnojIUCx4IiJDseCJiAzFgiciMhQLnojIUCx4IiJDseCJiAzFgiciMhQLnojIUCx4IiJDseCJiAzFgiciihOPx4PKykp4PJ64fD8WPBGRBTweD5555hkMGjQIy5Ytw0MPPQS32+23TFVVFQoLC1FVVRWXTLzgBxFRL5SXl+PWW28FAFxyySVwu9348ssvAQCLFi0CAPTt29fvYjAulwsVFRVwuVxxyciCJyLqRktLCzIzM7td5ujRowCA8847DwMGDMADDzyAY8eOobi42G85h8OBadOmxSxrVyx4IiKvuro6XHHFFRF/3SWXXIJ///vf2LFjB3JycmKQrHe4DZ6IklZtbS1ExHeLtNwfe+wxKKVw5MgRtLS02KrcARY8WaClpQV5eXkYOXIkGhsbdcchCqpzkXfcIuF0OqGU8rvdd999MUprDRY8RW3WrFl4//33ceDAAYwcOdL3wzNnzhzd0ShJXXTRRVGVOYCAMm9ra4tB0thiwVPU1q5dizFjxmDAgAE4ffq0b/6qVat6/cNFFK7GxkYMGjTIr8z/9a9/RfQaw4YNCyh0E7DgKWoZGRmora1FY2Mjxo8fH3QZFj3Fyg033OA7iiVcHSWel5cHpRQOHToUo3R6seDJMmlpaXj33Xfx4IMPhlymY6cWkVVGjBgR8rmFCxcGjMxNGZ2HgwVPlvv973/f4w8RR/Rkleeffx5FRUU4ceJEQJE/+eSTuuNpxYKnmAlntCQi2Lx5c5wSkYnS0tKwZs0apKWl6Y5iOyx4irmeiv7GG2+MYxqi5MGCp7jp2KnVVb9+/TSkITIfC57irmNE/8EHHyA1NRW7du3SHYnISDwXDWmTm5vrO/seEVmPI3giIkOx4ImIDJVQBd/1clcejwdr1qzBgw8+GHDlFCKiZJdQBd/1cldVVVX48Y9/jKVLl2Ls2LEoKirC2WefjQEDBgQ9c1zXW0VFheZ/ERFR7CRUwXe93JXL5cLf/vY3XHrppdi/fz/Wrl2LM2fO4OTJk2G93syZM8P6RdD5nNFDhgyJ5T+RiMgyCVXwHZe7cjgcvulbbrkFb7/9NqZPn45Zs2bhrLPOQv/+/WOWobGxscdfCNnZ2Xj++efjduV0IqJgjDhMMi0tDevXrw97eafTia+++ipmeT777DPcfvvtuOCCC+J6/UUios4SagRvFbfbHfQMc6FuwT592Z2srCysXr06bldOJyIKxogRfDwk0ylGicgMSTmCJzJZ3759Q+4feu6553Duuediz549umNSHLDgiRKI2+3GtGnT/I7s6nr75ptvQn79L37xC7S1teHaa6+NY2rShQVPlEDKysrwyiuv9Prrn332WaSmpuKtt96yMBXZlSXb4EVkKoBlAPoCeE4ptdSK1yUif8XFxRFtXgm27+iuu+6yMhLZWNQjeBHpC+BPAL4PYBSAW0VkVLSvS0SBnE4nKisrfReL7ulGyc2KTTTjATQopQ4ppTwAygHcbMHrEhFRFCTa3/IiMhPAVKXUXd7pnwL4jlLql12WmwtgLgCkp6fnlZeXA2jfaeR0OqPKEGvMaJ1EyMmM1mBGa3TOWFBQUKuUGhv2F0fygZ8QfwLORPt2947pnwL4Yw8fHFIdqqurld0xo3USISczWoMZrdE5I4D3VAT9bMUmmiMAsjpND/bOIyIijawo+BoAI0RkmIg4AMwGsMmC1yUioihEfZikUuqMiPwSQBXaD5NcqZT6OOpkREQUFUuOg1dKvQrgVStei4iIrMFPshIRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY8EZGhWPBERIZiwRMRGYoFT0RkKBY82V55eTlEBOXl5bqjkI20trbilltuQWtrq+4otsWCJ1tLT0/HrbfeCgC+eyIAWLBgAV566SUMHDgQIgIRwY9+9CPdsWyFBU+29dBDD+H48eO6Y5BNLV++PGDexo0bfWUvIhpS2QsLnmzr0Ucf9ZteuHChpiRkR2lpabjzzju7XSbZy54FT7YU7AfyySef1JCE7GzlypVQSmH27Nk9LttR9H36JE/tJc+/lBJGsHJXSmlIQonixRdfhFIqrPeJUspX9s3NzXFIp89ZugMQEVmpc8n3tGnm6NGjvmVMHERwBK9JS0sLrrnmGrS0tOiOYiscvZOVOkb14byHTNxez4KPs/nz50NEkJmZiR07dmD69Om6I9kGy71dQ0MD0tPT4XA4UFNTozuOMXpT9iNGjIhDsthhwcdBa2ur7w3z9NNP+z139dVXa0pFdlVQUIDjx4/j66+/xvjx43XHMVJH0WdnZ3e7XENDg+9n9/HHH49TOuuw4GOo440xcODAoM9Pnz4dJSUlcU5lT8HWUTKO3gGgurrab9qkTQZ2c9FFF/nK/rHHHut22fvvvx8ign79+mHPnj1xShgdFnwM9LQdLyMjAydOnMD69evhdDrjmMyeampqAj5unqzlDgA5OTkB81jysXfffff5yn737t0hlzt9+jSuuuoq3HbbbZgxY4atT5XAgrdQODtolFJobm5GWlpanFLZ33e+8x2/6WQu9w6LFy8OmMeSj59x48b5yv6DDz4IuswLL7yADRs24Lvf/S4aGhpsedAECz5K559/ftjFzuIK5Ha7/aY3btyoKYm9cNOdfeTm5vqVfUpKCvr16+fbfv/JJ5+goKAAO3bswKxZszSn9ceC76WOUv/iiy+6XY7FHlpjYyOGDh0KpRT69OmDnTt34oc//KHuWLYR7H3DUbxeubm5OHnyJE6dOoUPPvgA06dPx69+9StUV1dj4sSJWLt2LYD2gcuSJUsCBjDxxg86RSicH7DFixdzBBaGqVOn4sSJExg4cCD++c9/cn9EEB2fuuxMRAJ2xFL8paWlYf369b7p7du3+x6XlZWhtLQUHo8HDocDxcXFWt7fLPgwfPXVV2EVO0fqkXnttdcwdepUvPbaayz3CNXX12Py5Mm6Y1AIxcXFAACPx4PS0lIAeja7seC7MWXKFFRXV/d4/CuLvXeys7NRV1enO4btBRvFnzx5UlMaCofT6URJSQncbrdvBK8Dt8EHcc899/T4Z/DFF1/M7esUN9wen5g6il7XX6gs+E7mzJkDEcFTTz0VcpmOUj927FgckxEFL/mpU6dqSEKJIukLvrW1Fddffz1EBKtWrQq6TOdPuxHpdPfdd/tNV1VVobGxUVMasrukLviamhoMHDgQW7duDfr88uXLwzpfBVG8/OlPf8KgQYP85l122WWa0pDdJW3Bu91uTJgwIWB+fn4+Tpw4AaUU5s+fryEZUfeamprQv39/3/SpU6fw5ptvakxEdpVUBd/5HOxlZWU4c+aM7wNLO3fuhFIKO3bs4GkEyPYuv/xyXHzxxb7pKVOmaExDdpVUh0nOmjXL93HizZs3A4C2DyAQRWvv3r3IzMwE0H7KDKKujB3BezweVFZWwuPx+OatXbvW93Fi3YcvEUUrIyMDBw4cwODBg7F161ZbfDSe7MXYgq+qqkJhYSGqqqp88zIyMrB9+3ZkZGRoTEZknZycHHz22WeoqKhAaWkpysrKdEciGzF2E43L5UJFRQVcLpfuKEQx1/FJSV2fmCR7MrbgHQ4Hpk2bpjsGUVx0bHIk6szYTTRERMmOBU9EZKioCl5EZonIxyLyjYiMtSoUERFFL9oR/D8AzADwlgVZiIjIQlHtZFVK1QM8bSkRkR1xGzwRkaGkp1PgisgbAIJ9MuhhpdRG7zLbANynlHqvm9eZC2AuAKSnp+eVl5cDaD/pl90/TcqM1kmEnMxoDWa0RueMBQUFtUqp8Pd3dpznPJobgG0Axoa7fF5enupQXV2t7I4ZrZMIOZnRGsxojc4ZAbynIuhmbqIhIjJUtIdJTheRJgDfBfB3Eanq6WuIiCg+oj2KZgOADRZlISIiC3ETDRGRoVjwRESGYsETERmKBU9EZCgWPBGRoVjwRESGYsETERmKBU9EZCgWPBGRoVjwRESGYsETERmKBU9EZCgWPBGRoVjwRESGYsETERmKBU8+brcbS5Ysgdvt1h2FiCzAgie8/fbbEBGkpqaitLQUZWVluiORzTU0NCArKwsNDQ26o1A3WPCE/Px8v+ni4mJNSShRFBQUoKmpCSNGjEBFRYXuOBQCCz7JjRo1ym/6iSeegNPp1JSGEkV1dbXv8cyZM1FUVKQxDYXCgk9iWVlZqK+v95u3aNEiTWkokeTk5PhNr127FjNnztSUhkJhwSexpqYmv+lXX31VUxJKRE888YTfdEVFBVpbWzWloWBY8ElKRPymMzMz8f3vf19TGkpEixYtwsKFC/3mDRw4UFMaCoYFn4S6ljsAHD16VEMSSnRPPvlkwLxg7y/SgwWfZIJtJy0pKdGQhEyhlAqYx5K3BxZ8kgl2SNvixYs1JCGTDBs2LGBebW2thiTUGQs+iQQbVQUbfRHQ2NiIUaNGobGxUXeUhHDo0KGg82tqauKchDpjwScJlntkJkyYgPr6ekyYMEF3lIQR7P00fvx4DUmoAwueKIgjR4743VN4uD3eXljwSYCjd4onlrx9sOANx3InHQYMGBAwjyUffyx4g82ZMydg3rx58zQkoWQT6pTTmzdvjnOS5MaCN9iqVasC5q1YsUJDEkpGeXl5AfNuvPFGDUmSFwveUNw0Q3bA7fF6seANNGXKlIB5LHfShSWvDwveQJ3P1Q0AI0eO1JSEqN2VV14ZMO+mm27SkCS5sOANM2TIkIB5+/fv15CE6D/27NkTcGTN3//+d55eOMZY8Aa59957Az5az00zZBfBjqzh6YVjiwVvCKUU/vCHP/jNe/HFFzWlIQou2IBj8uTJ8Q+SJFjwhjh48KDf9MKFCzF79mxNaYhC61ryb775Jh5//HFNaczGgjfAb3/7W3zxxRe+6eHDhwe9EAORXXQ9RfX999+Puro6TWnMxYJPcI2Njfjd737nmx4zZkzAaJ7IbkpKSvDAAw/4zbvqqqs0pTEXCz7BXXvttb7H5513Ht58802NaYjCV1ZWhmuuucY37fF48Pbbb2tMZB4WfAJraGjA4cOHfdOHDh2C0+nUmIgoMm+99RYWLVrkm87Pz+cgxUIs+ATWefSTmpqKtLQ0jWmIeueJJ57Azp07fdOTJ09GQ0ODxkTmYMEnqJaWFt+HRAYMGIBvfetbmhMR9V7XK2eNGDGCl0u0AAs+AbndbowbNw4ejwcpKSmoq6tD3759dcciisq2bdv8pq+//no9QQzCgk8wra2tGD9+PJqamjB48GAcOnQI2dnZumMRRW3SpEnYvXu3b7qxsZGj+Cix4BPMggULUF9fj8svvxz19fXIyMjQHYnIMuPGjUNzczNSUlJw+vRp5Ofnw+Px6I6VsFjwCWb58uUoKirCjh07eMQMGSkjIwP79u3D4MGD0dLSgqqqKt2REhYLPkF4PB5UVlbC6XRizZo1PGImjrruAKTYy87OxsGDB7F+/Xq4XC7dcRIWCz5BVFVVobCwkKMZDXbt2qU7QlJyOByYNm0aHA6H7igJiwWfIFwuFyoqKjiaiZN169bpjkCddPwFy+3xkWHBJwiOZuKrsLBQdwTqhH/B9g4Lnohsz+Vyoby8HF9//TVH8RFgwROR7TkcDpx99tmYPXs2R/ERYMETUULgfqjIseCJQkhJSfG7J724HypyLHiiEM4991y/e6JEw4InCuHee+/1uydKNCx4ohA2btzod0+UaFjwRCGsX78eEydOxPr163VHIeqVs3QHILKrjIwMbN++XXcMol6LagQvIo+JyD4R+VBENojI+VYFIyKi6ES7ieZ1AKOVUt8G8AmAB6OPRGQPPP8JJbqoCl4ptUUpdcY7+Q6AwdFHIrIHnv+EEp2VO1nnANhs4esRaZWfn4/p06cjPz9fdxSiXhGlVPcLiLwBINh14R5WSm30LvMwgLEAZqgQLygicwHMBYD09PS88vJyAO0XkLb7lYmY0TqJkLMj49GjR9Hc3IzMzExccsklumP5SaT1aGeJlrGgoKBWKTU27C9WSkV1A3AHgF0A+of7NXl5eapDdXW1sjtmtE4i5OzI2NbWphYvXqza2tr0BgoikdajnSVaRgDvqQj6OarDJEVkKoAHAExSSp2M5rWI7MbpdKKkpER3DKJei3Yb/B8BpAJ4XUT2iMgKCzIREZEFohrBK6VyrApCRETW4qkKiIgMxYInIjIUC56IyFAseCIiQ7HgiYgMxYInIjIUC56IyFAseCIiQ7HgiYgMxYInIjJUj6cLjsk3FfkfAIe9kxcC+FfcQ0SGGa2TCDmZ0RrMaI3OGYcopS4K9wu1FLxfAJH3VCTnN9aAGa2TCDmZ0RrMaI1oMnITDRGRoVjwRESGskPBP6M7QBiY0TqJkJMZrcGM1uh1Ru3b4ImIKDbsMIInIqIYiHvBi8hjIrJPRD4UkQ0icn6I5aaKyH4RaRCR38Q54ywR+VhEvhGRkHuvReSfIvKR93KF79k0o7b16P3+aSLyuogc8N5fEGK5f3vX4x4R2RSHXN2uFxE5R0TWeJ9/V0SGxjpTMGHkvENE/qfTursrzvlWishxEflHiKdEz6gAAAQ4SURBVOdFRJ705v9QRMbEM1+YGSeLyBed1uH/1pAxS0SqRaTO+3P9v4IsE/m6jOQK3VbcAHwPwFnex2UAyoIs0xfAQQDDATgA7AUwKo4ZLwdwKYBtAMZ2s9w/AVwY73UYbkbd69Gb4f8C+I338W+C/X97n3PHMVOP6wXA3QBWeB/PBrBGw/9xODnvAPBHHe9B7/e/FsAYAP8I8fyNADYDEABXA3jXhhknA3hF1zr0ZsgEMMb7OBXAJ0H+ryNel3EfwSultiilzngn3wEwOMhi4wE0KKUOKaU8AMoB3BzHjPVKqf3x+n69EWZGrevR62YAq72PVwP4UZy/fzDhrJfOudcBuE5EJI4ZAXv8/3VLKfUWgNZuFrkZwPOq3TsAzheRzPikaxdGRu2UUs1Kqfe9j9sA1AMY1GWxiNel7m3wc9D+G6mrQQA+6zTdhMB/rB0oAFtEpFZE5uoOE4Qd1mO6UqrZ+7gFQHqI5fqJyHsi8o6IxPqXQDjrxbeMd0DyBYCBMc7VVbj/f4XeP9nXiUhWfKKFzQ7vwXB8V0T2ishmEblCZxDv5sCrALzb5amI1+VZVgbrICJvAMgI8tTDSqmN3mUeBnAGwAuxyNCTcDKGYaJS6oiIXAzgdRHZ5x0t2CljzHWXs/OEUkqJSKjDtoZ41+VwAP8tIh8ppQ5andVAlQBeVEqdFpF5aP+rY4rmTInmfbS//9wiciOAlwGM0BFERJwAKgAsUkp9Ge3rxaTglVLXd/e8iNwB4CYA1ynvxqUujgDoPBIZ7J1nmZ4yhvkaR7z3x0VkA9r/pLas4C3IGPP1CHSfU0SOiUimUqrZ++fk8RCv0bEuD4nINrSPYGJV8OGsl45lmkTkLADnATgRozyh9JhTKdU503No3+dhJ3F5D0ajc5EqpV4VkadE5EKlVFzPUSMiZ6O93F9QSq0PskjE61LHUTRTATwA4IdKqZMhFqsBMEJEhomIA+07uWJ+ZEUkRGSAiKR2PEb7zuOge+k1ssN63ATgdu/j2wEE/OUhIheIyDnexxcCyAdQF8NM4ayXzrlnAvjvEIORWOoxZ5dtsD9E+7ZbO9kE4GfeI0CuBvBFp012tiAiGR37V0RkPNp7Ma6/zL3f/88A6pVS/xViscjXpYa9xQ1o3460x3vrOFLhEgCvdtlj/AnaR3EPxznjdLRv3zoN4BiAqq4Z0X5kw17v7WM7ZtS9Hr3ffyCArQAOAHgDQJp3/lgAz3kfTwDwkXddfgTg53HIFbBeAPwftA88AKAfgLXe9+tuAMPjve7CzPmo9/23F0A1gMvinO9FAM0Avva+H38OYD6A+d7nBcCfvPk/QjdHpWnM+MtO6/AdABM0ZJyI9n16H3bqxhujXZf8JCsRkaF0H0VDREQxwoInIjIUC56IyFAseCIiQ7HgiYgMxYInIjIUC56IyFAseCIiQ/1/FXr3Guh0L5wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAPB05BoN0Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance(model, true):\n",
        "  onehot_true = one_hot(true, M)\n",
        "  y_pred = model.predict(onehot_true)\n",
        "  indices = np.argmax(y_pred, axis=1)\n",
        " \n",
        "  cm = confusion_matrix(true, indices)\n",
        "  f1 = f1_score(true, indices, average=None)\n",
        "  acc = accuracy_score(true, indices)\n",
        "\n",
        "  df_cm = pd.DataFrame(cm)\n",
        "  \n",
        "  return df_cm, f1, acc\n",
        "\n",
        "def plot_confusion_matrix(cm):\n",
        "  sns.set(font_scale=0.7) # for label size\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 8})\n",
        "  plt.title('Confusion matrix ')\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgBSS7KYsvcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm, f1, acc = performance(ae, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg4RvMraiGw1",
        "colab_type": "code",
        "outputId": "29d1c08f-c002-411e-9dd4-48c55c797d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9HssyJeiP3J",
        "colab_type": "code",
        "outputId": "2a6695d2-0508-4c8a-dfac-9ca98318fd60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99541486, 0.99896125, 0.99861881, 0.99572469])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqz7ah9DjA-w",
        "colab_type": "code",
        "outputId": "2aaaeff1-0018-44a8-e119-331ab4d2a06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99718"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4raoZHgjEGe",
        "colab_type": "code",
        "outputId": "00b75914-88bd-4119-9e58-e1cf5ec9ef12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1.sum()/len(f1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9971799022389083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASCKDZ_RjQJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}